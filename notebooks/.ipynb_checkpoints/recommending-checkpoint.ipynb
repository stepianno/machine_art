{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The first portion of this notebook is devoted to creating the recommendation system which will later be used as part of the Flask App. The second portionn is dedicated to creating brand new images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Input\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model, load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from scipy import spatial\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from skimage import io\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To begin, it's essentially to load in the encoder which is used to condense the images. Once encoded, recommendations can comfortably made by calculating cosine distance between encodings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_extractor = load_model('feature.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Here I connect to my modern art images and get the encodings for each using the neural net*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art = os.listdir('moma')\n",
    "art.remove('.DS_Store') #Not an image, this one was causing issues\n",
    "ad_features = []\n",
    "for work in art:\n",
    "    x = cv2.resize(cv2.imread('moma/'+work),(224,224))\n",
    "    x = x/255\n",
    "    ad_features.append(feature_extractor.predict(x.reshape(1,224,224,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I convert my encodings to a numpy array in order to reshape each to a flat array. This is necessary for calculating cosine distance as well as clustering for image generation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_featured = np.array(ad_features)\n",
    "ad_featured = ad_featured.reshape(len(ad_featured), np.prod(ad_featured.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_featured.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I save the encodings for use in the recommender app*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ad_featured, open('art_features.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The following line of code requires an image address, converts it to a numpy array of 224x224x3 with cv2, creates the encoding of that image, calculates the cosine distance of every image within the corpus, and produces the indices of the top 5 closely related images, which can then easily be used to display the images themselves. This is the crux of how the recommender is created with the app.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = io.imread('{image_address}')\n",
    "x = cv2.resize(image,(224,224))\n",
    "x = x/255\n",
    "y = feature_extractor.predict(x.reshape(1,224,224,3))\n",
    "y = y.reshape(1, np.prod(y.shape))\n",
    "dist = spatial.distance.cdist(y, ad_featured, metric='cosine')[0]\n",
    "ind = dist.argsort()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[art[ind[0]], art[ind[1]], art[ind[2]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open('static/moma/'+art[ind[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The code below prints out the artist's name, the title, and year for visual purposes within the app.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name, title, year = re.sub('-',' ',art[255][:-5]).split('_')\n",
    "print(name+'\\n'+title+'\\n'+year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This next portion of code is dedicated to creating brand new images by clustering the encodings and aggregating on the clusters. The aggregations are then sent through the decoder half of the autoencoder to produce brand new images.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_maker = load_model('imager.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I use PCA to reduce dimensionality of the encodings and then cluster paintings by assigning each to its majority feature, I then collect that groups that consist of at least two paintings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "works = pca.fit_transform(ad_featured)\n",
    "tops = np.argmax(works, axis=1)\n",
    "counter = Counter(tops)\n",
    "groups = [i for i in counter.keys() if counter[i] >= 2]\n",
    "groups.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Here I aggregate all the images in each cluster, either with max, mean, or min to get different results, and prepare them to print. Most images look outrageous, but a handful end up looking really cool. Those are the ones I save.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = []\n",
    "for i in groups:\n",
    "    ind = np.where(tops==i)\n",
    "    new = np.max(ad_featured[ind], axis=0) #type of aggregation is determined in this line\n",
    "    new = new.reshape(1,28,28,16)\n",
    "    new_image = image_maker.predict(new)\n",
    "    generated.append(new_image.reshape(224,224,3))\n",
    "\n",
    "plt.figure(figsize=(18,80))\n",
    "for i in range(len(groups)):\n",
    "    plt.subplot((len(groups))//2+1, 2, i+1)\n",
    "    plt.imshow(generated[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Because the first few groups contained far too many images (over 100) to produce anything interesting, I go a bit deeper and cluster each of those clusters to extract some good results. Generally, a cluster with three to six images creates the most worthwhile results. I use more-or-less the same code for each of the subgroups below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.where(tops==0)\n",
    "c0 = ad_featured[ind]\n",
    "pca0 = PCA(n_components=50)\n",
    "works0 = pca0.fit_transform(c0)\n",
    "top0 = np.argmax(works0, axis=1)\n",
    "count0 = Counter(top0)\n",
    "group0 = [i for i in count0.keys() if count0[i] >=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated = []\n",
    "for i in group0:\n",
    "    ind = np.where(tops==0)[0][np.where(top0==i)]\n",
    "    new = np.max(ad_featured[ind], axis=0)\n",
    "    new = new.reshape(1,28,28,16)\n",
    "    new_image = image_maker.predict(new)\n",
    "    generated.append(new_image.reshape(224,224,3))\n",
    "\n",
    "plt.figure(figsize=(18,80))\n",
    "for i in range(len(group0)):\n",
    "    plt.subplot((len(group0))//2+1, 2, i+1)\n",
    "    plt.imshow(generated[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Because the first cluster still contained too many images, I went ahead and further clustered the images from that group as well*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.where(tops==0)[0][np.where(top0==0)]\n",
    "c00 = ad_featured[ind]\n",
    "pca00 = PCA(n_components=20)\n",
    "works00 = pca00.fit_transform(c00)\n",
    "top00 = np.argmax(works00, axis=1)\n",
    "count00 = Counter(top00)\n",
    "group00 = [i for i in count00.keys() if count00[i] >=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = []\n",
    "for i in group00:\n",
    "    ind = np.where(tops==0)[0][np.where(top0==0)][np.where(top00==i)]\n",
    "    new = np.min(ad_featured[ind], axis=0)\n",
    "    new = new.reshape(1,28,28,16)\n",
    "    new_image = image_maker.predict(new)\n",
    "    generated.append(new_image.reshape(224,224,3))\n",
    "\n",
    "plt.figure(figsize=(18,80))\n",
    "for i in range(len(group00)):\n",
    "    plt.subplot((len(group0))//2+1, 2, i+1)\n",
    "    plt.imshow(generated[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*And again for the second group*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.where(tops==1)\n",
    "c1 = ad_featured[ind]\n",
    "pca1 = PCA(n_components=50)\n",
    "works1 = pca1.fit_transform(c1)\n",
    "top1 = np.argmax(works1, axis=1)\n",
    "count1 = Counter(top1)\n",
    "group1 = [i for i in count1.keys() if count1[i] >=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated = []\n",
    "for i in group1:\n",
    "    ind = np.where(tops==1)[0][np.where(top1==i)]\n",
    "    new = np.max(ad_featured[ind], axis=0)\n",
    "    new = new.reshape(1,28,28,16)\n",
    "    new_image = image_maker.predict(new)\n",
    "    generated.append(new_image.reshape(224,224,3))\n",
    "\n",
    "plt.figure(figsize=(18,80))\n",
    "for i in range(len(group1)):\n",
    "    plt.subplot((len(group1))//2+1, 2, i+1)\n",
    "    plt.imshow(generated[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*once more for a third*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.where(tops==2)\n",
    "c2 = ad_featured[ind]\n",
    "pca2 = PCA(n_components=50)\n",
    "works2 = pca2.fit_transform(c2)\n",
    "top2 = np.argmax(works2, axis=1)\n",
    "count2 = Counter(top2)\n",
    "group2 = [i for i in count2.keys() if count2[i] >=2]\n",
    "group2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generated = []\n",
    "for i in group2:\n",
    "    ind = np.where(tops==2)[0][np.where(top2==i)]\n",
    "    new = np.max(ad_featured[ind], axis=0)\n",
    "    new = new.reshape(1,28,28,16)\n",
    "    new_image = image_maker.predict(new)\n",
    "    generated.append(new_image.reshape(224,224,3))\n",
    "        \n",
    "plt.figure(figsize=(18,80))\n",
    "for i in range(len(group2)):\n",
    "    plt.subplot((len(group1))//2+1, 2, i+1)\n",
    "    plt.imshow(generated[i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*After perusing the generated images, I pick out the ones I like and adjust this line below to save them. My preferred images are showcased in the virtual gallery within my Flask App.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.where(tops=={'desired_image'})\n",
    "new = np.max(ad_featured[ind], axis=0) #the type of aggregation must also be adjusted if necessary\n",
    "new = new.reshape(1,28,28,16)\n",
    "new_image = image_maker.predict(new)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(new_image.reshape(224,224,3))\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.tight_layout(pad=-1)\n",
    "plt.savefig('static/for_use/{image_name}.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The block below demonstrates the contrast of aggregating the clusters by the images to produce a new image as opposed to aggregating on the encodings and putting that aggregation through the decoder. The difference is vast!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conglom = []\n",
    "for i in np.where(tops=={'desired_image'}):\n",
    "    conglom.append(cv2.resize(cv2.imread('static/moma/'+art[i]),(224,224)))\n",
    "conglom = np.array(conglom)\n",
    "im = np.max(conglom, axis=0)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(im.reshape(224,224,3))\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.tight_layout(pad=-1)\n",
    "plt.savefig('static/for_use/bad.jpeg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
